{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "from rasterio.fill import fillnodata\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import gdal\n",
    "import rasterio\n",
    "import ogr\n",
    "import warnings\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from earthpy import clip\n",
    "from shapely.geometry import JOIN_STYLE\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from math import ceil\n",
    "from shapely.ops import unary_union, Polygon\n",
    "\n",
    "import scipy.spatial\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Datasets\n",
    "Select the workspace, this is the folder that will be used for the outputs. \n",
    "NOTE Select an empty folder as all the files will be deleted from the workspace \n",
    "\n",
    "You will also have to select the three datasets used in the analysis. These are:\n",
    "    \n",
    "1) Administrative boundaries.\n",
    "\n",
    "2) Agro Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output folder - Ideally, should be found in Output_data\\FAO_AgroMap_Crops\n",
    "messagebox.showinfo('AGRODEM Creating base grid', 'Output folder')\n",
    "workspace = filedialog.askdirectory()\n",
    "\n",
    "#Administrative boundaries - Ideally, should be found in Input_Data/admin_data\n",
    "messagebox.showinfo('AGRODEM Creating base grid', 'Select the administrative boundaries')\n",
    "filename_admin = (filedialog.askopenfilename(filetypes = ((\"shapefile\",\"*.shp\"),(\"all files\",\"*.*\"))))\n",
    "admin=gpd.read_file(filename_admin)\n",
    "\n",
    "#The output file of step 1 -  \"Prepping_Agro_Maps.ipynb\" is what should be used here. It should easily be found in Outputdata/Crop_Maps\n",
    "messagebox.showinfo('AGRODEM Creating base grid', 'Select the agro map')\n",
    "filename_agro = (filedialog.askopenfilename(filetypes = ((\"shapefile\",\"*.shp\"),(\"all files\",\"*.*\"))))\n",
    "agro=gpd.read_file(filename_agro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the target coordinate system\n",
    "\n",
    "\n",
    "Find the appropriate target crs from:  https://epsg.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = 'EPSG:32631'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensuring vectors are in the same coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprojecing to target coordinate system written above\n",
    "def target_crs(vectors,crs,workspace):   \n",
    "    vectors = vectors.to_crs(crs) \n",
    "    vectors.to_file(workspace, driver='ESRI Shapefile')  \n",
    "    return vectors\n",
    "\n",
    "agro_pr = agro.to_crs(crs)\n",
    "admin_pr = admin.to_crs(crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixgeometries(polygon):\n",
    "    #creates a valid representation of a given invalid geometry without losing any of the input vertices. \n",
    "    fix = polygon.buffer(0.001)\n",
    "    return fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing agro maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip agro map to place of interest\n",
    "clipped_agro = gpd.clip(agro_pr,admin_pr)\n",
    "\n",
    "#determining yield \n",
    "\n",
    "clipped_agro['yield'] =  clipped_agro['product_ha']  / clipped_agro['harv_area_']   \n",
    "\n",
    "#Calculating the area of each unit [ha]\n",
    "clipped_agro['area'] =  (clipped_agro['geometry'].area)/10000\n",
    "\n",
    "#Calculating the perimeter of each unit [km]\n",
    "clipped_agro[\"perimeter\"] = (clipped_agro[\"geometry\"].length)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating base point layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(gdf, height, cut=True):\n",
    "    \"\"\"\n",
    "    Return a grid, based on the shape of *gdf* and on a *height* value (in\n",
    "    units of *gdf*). If cut=False, the grid will not be intersected with *gdf*\n",
    "    (i.e it makes a grid on the bounding-box of *gdf*).\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf: GeoDataFrame\n",
    "        The collection of polygons to be covered by the grid.\n",
    "    height: Integer\n",
    "        The dimension (will be used as height and width) of the ceils to create,\n",
    "        in units of *gdf*.\n",
    "    cut: Boolean, default True\n",
    "        Cut the grid to fit the shape of *gdf* (ceil partially covering it will\n",
    "        be truncated). If False, the returned grid will fit the bounding box\n",
    "        of *gdf*.\n",
    "    Returns\n",
    "    -------\n",
    "    grid: GeoDataFrame\n",
    "        A collection of polygons.\n",
    "    \"\"\"\n",
    "   \n",
    "    xmin, ymin = [i.min() for i in gdf.bounds.T.values[:2]]\n",
    "    xmax, ymax = [i.max() for i in gdf.bounds.T.values[2:]]\n",
    "    rows = int(ceil((ymax-ymin) / height))\n",
    "    cols = int(ceil((xmax-xmin) / height))\n",
    "\n",
    "    x_left_origin = xmin\n",
    "    x_right_origin = xmin + height\n",
    "    y_top_origin = ymax\n",
    "    y_bottom_origin = ymax - height\n",
    "\n",
    "    res_geoms = []\n",
    "    for countcols in range(cols):\n",
    "        y_top = y_top_origin\n",
    "        y_bottom = y_bottom_origin\n",
    "        for countrows in range(rows):\n",
    "            res_geoms.append((\n",
    "                (x_left_origin, y_top), (x_right_origin, y_top),\n",
    "                (x_right_origin, y_bottom), (x_left_origin, y_bottom)\n",
    "                ))\n",
    "            y_top = y_top - height\n",
    "            y_bottom = y_bottom - height\n",
    "        x_left_origin = x_left_origin + height\n",
    "        x_right_origin = x_right_origin + height\n",
    "    if cut:\n",
    "        if all(gdf.eval(\n",
    "            \"geometry.type =='Polygon' or geometry.type =='MultiPolygon'\")):\n",
    "            res = GeoDataFrame(\n",
    "                geometry=pd.Series(res_geoms).apply(lambda x: Polygon(x)),\n",
    "                crs=gdf.crs\n",
    "                ).intersection(unary_union(gdf.geometry))\n",
    "        else:\n",
    "            res = GeoDataFrame(\n",
    "                geometry=pd.Series(res_geoms).apply(lambda x: Polygon(x)),\n",
    "                crs=gdf.crs\n",
    "                ).intersection(unary_union(gdf.geometry).convex_hull)\n",
    "        res = res[res.geometry.type == 'Polygon']\n",
    "        res.index = [i for i in range(len(res))]\n",
    "        return GeoDataFrame(geometry=res)\n",
    "\n",
    "    else:\n",
    "        return GeoDataFrame(\n",
    "            index=[i for i in range(len(res_geoms))],\n",
    "            geometry=pd.Series(res_geoms).apply(lambda x: Polygon(x)),\n",
    "            crs=gdf.crs\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the desired output resolution in the \"height\" variable, the higher the resolution the longer it takes to run. \n",
    "# For 250m , height = 250 ; for 1km, height =1000; for 10km, height = 10000, etc.\n",
    "\n",
    "height = 1000\n",
    "\n",
    "grid=make_grid(clipped_agro,height, cut=False)\n",
    "\n",
    "#clip point layer and join based on location \n",
    "clipped_grid=gpd.overlay(grid,clipped_agro, how='intersection', make_valid=True, keep_geom_type=True)\n",
    "\n",
    "#reproject layer to target coordinate system\n",
    "clipped_grid_pr= clipped_grid.to_crs(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding point coordinates to layer\n",
    "def keep_first(geo):\n",
    "   if geo.geom_type == 'Polygon':\n",
    "       return geo\n",
    "   elif geo.geom_type == 'MultiPolygon':\n",
    "       return geo[0]\n",
    "\n",
    "clipped_grid_pr.geometry = clipped_grid_pr.geometry.apply(lambda _geo: keep_first(_geo))\n",
    "\n",
    "clipped_grid_pr['geometry']=clipped_grid_pr.centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditioning(clipped_grid_pr, workspace):\n",
    "    agro_update = clipped_grid_pr.to_crs({ 'init': 'epsg:4326'}) \n",
    "\n",
    "    \n",
    "    \n",
    "    agro_update = agro_update.rename(columns={\"id\": \"id\", \"admin2\" : \"state\", \"country_co\":\"c_code\",\n",
    "                                              \"country\":\"country\",\"crop\":\"crop\",\"year\":\"year\",\n",
    "                                              \"harv_area_\":\"harv_area_ha\", \"yield\":\"yield\",\n",
    "                                              \"product_ha\":\"prduction_ha\",\"area\":\"statearea_ha\",\n",
    "                                              \"perimeter\":\"perimeter_km\"})\n",
    "        \n",
    "    agro_update[\"X_deg\"] = agro_update.geometry.centroid.x\n",
    "    \n",
    "    agro_update[\"Y_deg\"] = agro_update.geometry.centroid.y\n",
    "    \n",
    "    agro_update.to_file(workspace + r\"\\output.shp\", driver='ESRI Shapefile')\n",
    "    agro_update.to_file(workspace + r\"\\output.csv\", driver='CSV')\n",
    "    print(datetime.datetime.now())\n",
    "    return agro_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-23 18:17:54.438059\n"
     ]
    }
   ],
   "source": [
    "agro_final = conditioning(clipped_grid, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
